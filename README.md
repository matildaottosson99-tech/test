Projektuppgift: Automatiserad data-pipeline 游
Kurs: Data Science | Grupp: [Namn p친 gruppmedlemmar]

Detta projekt bygger en automatiserad datapipeline som h칛mtar dagliga transaktioner, normaliserar datan och lagrar den i en SQLite-databas. Datan visualiseras sedan i en Jupyter Notebook.

Projektstruktur
Vi anv칛nder uv f칬r att hantera projektet och dess beroenden.

dags/transaction_dag.py - Airflow DAG som sk칬ter h칛mtning och lagring.

koksgledje.db - SQLite-databasen (normaliserad).

analysis.ipynb - Jupyter Notebook med visualiseringar.

pyproject.toml - Projektdefinition och beroenden.

Pipeline-fl칬de
Extract: H칛mtar transaktioner (CSV) fr친n schizoakustik.se med requests.

Transform: - Konverterar datum till standardformat.

Filtrerar ut data som redan finns i databasen (baserat p친 TransactionDate).

Normaliserar datan till tv친 tabeller: Transactions och TransactionDetails.

Load: Sparar ny data till koksgledje.db.

Visualize: Jupyter Notebook l칛ser fr친n databasen och genererar grafer.

Installation & K칬rning
F칬r att k칬ra detta projekt lokalt:

Installera beroenden:

Bash
uv sync
Starta Airflow: (Beskriv h칛r hur ni k칬r Airflow, t.ex. standalone eller via Docker).

Databasmodell
Datan 칛r normaliserad i f칬ljande tabeller:

Transactions: TransactionID (PK), TransactionDate, CustomerID.

TransactionDetails: TransactionID (FK), ProductID, Quantity, Price.
